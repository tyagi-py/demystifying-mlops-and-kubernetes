# Demystifying MLOPs and Kubernetes

We had a discussion on MLOps yesterday, in the learning carnival. You can find the codebase used in the session here.



## Description

Central thoughts:
- ML model lifecycle.
- ML model serving  patterns & deployment strategies.
- Serving a sentiment analysis model in "model-as-service" pattern using FastAPI & docker.
- Load & Stress testing of the same model service, checking latency and TAT using JMeter.
- Scale-up the same model to cater 10000+ users using Kubernetes and load-balancing.


### Dependencies

Any operating system with docker installed, For kubernetes: any cloud based kubernetes service.

## Authors

Contributors names and contact info

Sumit Tyagi [@tyagi.py](https://www.instagram.com/tyagi.py/)
